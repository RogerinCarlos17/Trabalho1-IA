{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ib6MLqcX4JhD",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import da Base Dados para o Exercicio 1"
      ],
      "metadata": {
        "id": "FbUoDZfbmTnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "communities_and_crime = fetch_ucirepo(id=183)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = communities_and_crime.data.features\n",
        "y = communities_and_crime.data.targets\n",
        "\n",
        "# metadata\n",
        "print(communities_and_crime.metadata)\n",
        "\n",
        "# variable information\n",
        "print(communities_and_crime.variables)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mQekiDqUYO1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pré-processamento dos dados, treinamento de um modelo de regressão linear e avaliação do modelo."
      ],
      "metadata": {
        "id": "RuwnlsE0mqh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Concatenar as variáveis independentes e a variável alvo\n",
        "df = pd.concat([X, y], axis=1)\n",
        "\n",
        "# Identificar as colunas com valores faltantes\n",
        "colunas_com_faltantes = df.columns[df.isnull().any()].tolist()\n",
        "\n",
        "# Estratégias para lidar com valores faltantes (escolha uma ou combine):\n",
        "\n",
        "# 1. Remover linhas com valores faltantes (simples, mas perde dados)\n",
        "# df_limpo = df.dropna()\n",
        "\n",
        "# 2. Imputação usando a média para variáveis numéricas\n",
        "colunas_numericas = df.select_dtypes(include=['number']).columns\n",
        "imputador = SimpleImputer(strategy='mean')  # Usar média, mediana ou mais_frequente\n",
        "df[colunas_numericas] = imputador.fit_transform(df[colunas_numericas])\n",
        "\n",
        "# Separar variáveis independentes (X) e variável alvo (y) após lidar com dados faltantes\n",
        "X = df.drop('ViolentCrimesPerPop', axis=1)\n",
        "y = df['ViolentCrimesPerPop']\n",
        "\n",
        "# Converter colunas não numéricas para numéricas (usando codificação one-hot)\n",
        "X = pd.get_dummies(X, columns=X.select_dtypes(include=['object']).columns)\n",
        "\n",
        "# Dividir os dados em conjuntos de treinamento e teste\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Inicializar e treinar o modelo de regressão linear\n",
        "modelo = LinearRegression()\n",
        "modelo.fit(X_treino, y_treino)\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "y_predito = modelo.predict(X_teste)\n",
        "\n",
        "# Avaliar o modelo\n",
        "mse = mean_squared_error(y_teste, y_predito)\n",
        "print(f\"MSE: {mse}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "L6kgtEsGZ9l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculo das métricas RMSE e MAE para avaliar a performance do modelo de regressão linear."
      ],
      "metadata": {
        "id": "vBzcASONnKQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Prever no conjunto de treinamento\n",
        "y_treino_pred = modelo.predict(X_treino)\n",
        "\n",
        "# Calcular RMSE e MAE para o conjunto de treinamento\n",
        "rmse_treino = mean_squared_error(y_treino, y_treino_pred, squared=False)  # squared=False para RMSE\n",
        "mae_treino = mean_absolute_error(y_treino, y_treino_pred)\n",
        "\n",
        "print(f\"RMSE do Treinamento: {rmse_treino}\")\n",
        "print(f\"MAE do Treinamento: {mae_treino}\")\n",
        "\n",
        "# Calcular RMSE e MAE para o conjunto de teste (MSE já calculado acima)\n",
        "rmse_teste = mean_squared_error(y_teste, y_predito, squared=False)\n",
        "mae_teste = mean_absolute_error(y_teste, y_predito)\n",
        "\n",
        "print(f\"RMSE do Teste: {rmse_teste}\")\n",
        "print(f\"MAE do Teste: {mae_teste}\")\n"
      ],
      "metadata": {
        "id": "5dFpUlzRcd96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicação do PCA"
      ],
      "metadata": {
        "id": "7uaHWC8wnbna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Normalização das variáveis\n",
        "escalador = StandardScaler()\n",
        "X_treino_escalado = escalador.fit_transform(X_treino)\n",
        "X_teste_escalado = escalador.transform(X_teste)\n",
        "\n",
        "# Aplicar PCA\n",
        "pca = PCA(n_components=5)\n",
        "X_treino_pca = pca.fit_transform(X_treino_escalado)\n",
        "X_teste_pca = pca.transform(X_teste_escalado)\n",
        "\n",
        "# Razão da variância explicada\n",
        "variancia_explicada = pca.explained_variance_ratio_\n",
        "print(f\"Razão da Variância Explicada: {variancia_explicada}\")\n",
        "\n",
        "# Plotar a variância explicada\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(range(1, 6), variancia_explicada.cumsum(), marker='o', linestyle='--')\n",
        "plt.xlabel('Número de Componentes')\n",
        "plt.ylabel('Variância Explicada Cumulativa')\n",
        "plt.title('Variância Explicada pelos Componentes')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Treinar o modelo de regressão linear com PCA\n",
        "modelo_pca = LinearRegression()\n",
        "modelo_pca.fit(X_treino_pca, y_treino)\n",
        "\n",
        "# Previsões e avaliação\n",
        "y_pred_treino_pca = modelo_pca.predict(X_treino_pca)\n",
        "y_pred_teste_pca = modelo_pca.predict(X_teste_pca)\n",
        "\n",
        "rmse_treino_pca = mean_squared_error(y_treino, y_pred_treino_pca, squared=False)\n",
        "mae_treino_pca = mean_absolute_error(y_treino, y_pred_treino_pca)\n",
        "rmse_teste_pca = mean_squared_error(y_teste, y_pred_teste_pca, squared=False)\n",
        "mae_teste_pca = mean_absolute_error(y_teste, y_pred_teste_pca)\n",
        "\n",
        "print(f\"PCA - RMSE (Treinamento): {rmse_treino_pca}\")\n",
        "print(f\"PCA - MAE (Treinamento): {mae_treino_pca}\")\n",
        "print(f\"PCA - RMSE (Teste): {rmse_teste_pca}\")\n",
        "print(f\"PCA - MAE (Teste): {mae_teste_pca}\")\n",
        "\n",
        "# Regressão Polinomial\n",
        "polinomio = PolynomialFeatures(degree=2)  # Exemplo com grau 2\n",
        "X_treino_poli = polinomio.fit_transform(X_treino_pca)\n",
        "X_teste_poli = polinomio.transform(X_teste_pca)\n",
        "\n",
        "modelo_poli = LinearRegression()\n",
        "modelo_poli.fit(X_treino_poli, y_treino)\n",
        "y_pred_treino_poli = modelo_poli.predict(X_treino_poli)\n",
        "y_pred_teste_poli = modelo_poli.predict(X_teste_poli)\n",
        "\n",
        "rmse_treino_poli = mean_squared_error(y_treino, y_pred_treino_poli, squared=False)\n",
        "mae_treino_poli = mean_absolute_error(y_treino, y_pred_treino_poli)\n",
        "rmse_teste_poli = mean_squared_error(y_teste, y_pred_teste_poli, squared=False)\n",
        "mae_teste_poli = mean_absolute_error(y_teste, y_pred_teste_poli)\n",
        "\n",
        "print(f\"Regressão Polinomial - RMSE (Treinamento): {rmse_treino_poli}\")\n",
        "print(f\"Regressão Polinomial - MAE (Treinamento): {mae_treino_poli}\")\n",
        "print(f\"Regressão Polinomial - RMSE (Teste): {rmse_teste_poli}\")\n",
        "print(f\"Regressão Polinomial - MAE (Teste): {mae_teste_poli}\")\n"
      ],
      "metadata": {
        "id": "otRWAT6Ib_dM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# obter conjunto de dados\n",
        "htru2 = fetch_ucirepo(id=372)\n",
        "\n",
        "# dados (como dataframes do pandas)\n",
        "X = htru2.data.features\n",
        "y = htru2.data.targets\n",
        "\n",
        "# metadados\n",
        "print(htru2.metadata)\n",
        "\n",
        "# informações das variáveis\n",
        "print(htru2.variables)\n"
      ],
      "metadata": {
        "id": "dprbnuadYWJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "import time\n",
        "\n",
        "# transformando y em vetor 1D\n",
        "y = np.ravel(y)\n",
        "\n",
        "# lista para armazenar os resultados\n",
        "resultados = []\n",
        "\n",
        "# loop para realizar múltiplas execuções com diferentes valores de random_state\n",
        "for i in range(5):\n",
        "    # dividindo os dados em treino e teste\n",
        "    X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, train_size=6000, random_state=i)\n",
        "\n",
        "    # valores de k para o classificador KNN\n",
        "    valores_k = [3, 5, 7, 9, 11]\n",
        "    for k in valores_k:\n",
        "        # registrando o tempo de início\n",
        "        tempo_inicio = time.time()\n",
        "        # criando o classificador KNN com o valor de k\n",
        "        knn = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
        "\n",
        "        # dividindo os dados de treino para validação\n",
        "        X_treino_split, X_val, y_treino_split, y_val = train_test_split(X_treino, y_treino, test_size=0.5, random_state=i)\n",
        "\n",
        "        # treinando o modelo com os dados de treino\n",
        "        knn.fit(X_treino_split, y_treino_split)\n",
        "        # fazendo a predição nos dados de validação\n",
        "        y_pred_val = knn.predict(X_val)\n",
        "\n",
        "        # treinando o modelo com todos os dados de treino\n",
        "        knn.fit(X_treino, y_treino)\n",
        "        # fazendo a predição nos dados de teste\n",
        "        y_pred_teste = knn.predict(X_teste)\n",
        "\n",
        "        # registrando o tempo de fim\n",
        "        tempo_fim = time.time()\n",
        "\n",
        "        # calculando as métricas de avaliação\n",
        "        acuracia = accuracy_score(y_teste, y_pred_teste)\n",
        "        revocacao = recall_score(y_teste, y_pred_teste)\n",
        "        precisao = precision_score(y_teste, y_pred_teste)\n",
        "\n",
        "        # armazenando os resultados\n",
        "        resultados.append([k, acuracia, revocacao, precisao, tempo_fim - tempo_inicio, len(knn.classes_)])\n",
        "\n",
        "# criando um DataFrame com os resultados\n",
        "resultados_df = pd.DataFrame(resultados, columns=[\"k\", \"Acurácia\", \"Revocação\", \"Precisão\", \"Tempo\", \"Prototipos\"])\n",
        "# exibindo a média dos resultados por valor de k\n",
        "print(resultados_df.groupby('k').mean())\n"
      ],
      "metadata": {
        "id": "Fju7IO48Vt0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "nursery = fetch_ucirepo(id=76)\n",
        "\n",
        "X = nursery.data.features\n",
        "y = nursery.data.targets\n",
        "\n",
        "print(nursery.metadata)\n",
        "\n",
        "print(nursery.variables)\n"
      ],
      "metadata": {
        "id": "lbOm-HIWYfc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "\n",
        "# Assumindo que X e y já estão definidos a partir do código anterior (conjunto de dados Nursery)\n",
        "\n",
        "# Amostrando 10000 pontos de dados para treinamento\n",
        "random.seed(42) # Definindo a semente para reprodutibilidade\n",
        "indices_amostra = random.sample(range(len(X)), 10000)\n",
        "X_treino = X.iloc[indices_amostra]\n",
        "y_treino = y.iloc[indices_amostra]\n",
        "\n",
        "# Dados restantes para teste\n",
        "X_teste = X.drop(index=indices_amostra)\n",
        "y_teste = y.drop(index=indices_amostra)\n",
        "\n",
        "# Converter variáveis categóricas para numéricas usando one-hot encoding\n",
        "X_treino = pd.get_dummies(X_treino, columns=X_treino.select_dtypes(include=['object']).columns)\n",
        "X_teste = pd.get_dummies(X_teste, columns=X_teste.select_dtypes(include=['object']).columns)\n",
        "\n",
        "# Garantir que tanto os conjuntos de treino quanto de teste tenham as mesmas colunas após o one-hot encoding\n",
        "for col in X_treino.columns:\n",
        "    if col not in X_teste.columns:\n",
        "        X_teste[col] = 0\n",
        "for col in X_teste.columns:\n",
        "    if col not in X_treino.columns:\n",
        "        X_treino[col] = 0\n",
        "\n",
        "# Alinhar as colunas para consistência\n",
        "X_treino, X_teste = X_treino.align(X_teste, axis=1, join='inner')\n",
        "\n",
        "# Construir uma árvore de decisão com profundidade máxima=2 (dois níveis de nós de decisão)\n",
        "clf = DecisionTreeClassifier(max_depth=2, criterion='entropy')\n",
        "clf.fit(X_treino, y_treino)\n",
        "\n",
        "# Imprimir a estrutura da árvore (Você pode usar outras bibliotecas de visualização para uma melhor visualização)\n",
        "# print(clf.tree_) # Esta é uma representação de baixo nível, para depuração.\n",
        "\n",
        "# Avaliar o modelo no conjunto de teste\n",
        "y_pred = clf.predict(X_teste)\n",
        "acuracia = accuracy_score(y_teste, y_pred)\n",
        "print(f\"Acurácia: {acuracia}\")\n",
        "\n",
        "# Extrair as regras de decisão (representação simplificada)\n",
        "def obter_regras(árvore, nomes_features, nomes_classes):\n",
        "    regras = []\n",
        "    def percorrer(no, regra_atual):\n",
        "        if árvore.children_left[no] == -1:  # Nó folha\n",
        "            regra = regra_atual + f\" => {nomes_classes[np.argmax(árvore.value[no])]} \"\n",
        "            regras.append(regra)\n",
        "        else:\n",
        "            feature = nomes_features[árvore.feature[no]]\n",
        "            threshold = árvore.threshold[no]\n",
        "            percorrer(árvore.children_left[no], regra_atual + f\"{feature} <= {threshold} e \")\n",
        "            percorrer(árvore.children_right[no], regra_atual + f\"{feature} > {threshold} e \")\n",
        "    percorrer(0, \"\")\n",
        "    return regras\n",
        "\n",
        "# Obter as regras de decisão e imprimir\n",
        "regras = obter_regras(clf.tree_, X_treino.columns, clf.classes_)\n",
        "for regra in regras:\n",
        "    print(regra)\n"
      ],
      "metadata": {
        "id": "soLHfmApjMUj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}